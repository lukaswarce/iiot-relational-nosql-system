# Consultas de Ejemplo - SQL y Flux

**ColecciÃ³n de Queries Comentadas con PropÃ³sito PedagÃ³gico**

---

## ğŸ“‹ Ãndice

1. [Consultas MySQL (SQL)](#consultas-mysql-sql)
   - BÃ¡sicas SELECT
   - JOINs y Relaciones
   - Agregaciones y GROUP BY
   - Transacciones
   - Violaciones de Constraints
2. [Consultas InfluxDB (Flux)](#consultas-influxdb-flux)
   - Consultas BÃ¡sicas Time-Series
   - Agregaciones Temporales
   - Downsampling
   - DetecciÃ³n de AnomalÃ­as
   - Window Functions
3. [Comparaciones de Rendimiento](#comparaciones-de-rendimiento)
4. [Ejercicios de PrÃ¡ctica](#ejercicios-de-prÃ¡ctica)

---

## ğŸ—„ï¸ Consultas MySQL (SQL)

### 1. SELECT BÃ¡sico con WHERE

**Objetivo PedagÃ³gico**: Entender filtrado bÃ¡sico y estructura SELECT

```sql
-- Obtener todos los batches en progreso
SELECT 
    batch_code,
    product_name,
    status,
    target_quantity,
    actual_quantity,
    start_time
FROM production_batches
WHERE status = 'in_progress'
ORDER BY start_time DESC;
```

**ExplicaciÃ³n**:
- `SELECT`: Especifica columnas a retornar
- `FROM`: Tabla fuente de datos
- `WHERE`: Filtro condicional (solo batches en progreso)
- `ORDER BY DESC`: Ordena por fecha mÃ¡s reciente primero

**Resultado Esperado**:
```
batch_code       | product_name | status      | target_quantity | actual_quantity | start_time
-----------------|--------------|-------------|-----------------|-----------------|-------------------
BATCH_2026_008   | Widget B     | in_progress | 1000            | 750             | 2026-02-03 08:00:00
BATCH_2026_007   | Widget A     | in_progress | 1500            | 1200            | 2026-02-03 06:00:00
```

**Concepto Clave**: SQL es declarativo - dices QUÃ‰ quieres, no CÃ“MO obtenerlo.

---

### 2. JOIN - Relacionar Tablas

**Objetivo PedagÃ³gico**: Entender relaciones Foreign Key y JOIN operations

```sql
-- Obtener batches con informaciÃ³n de la lÃ­nea de producciÃ³n
SELECT 
    pl.line_name,
    pl.location,
    pb.batch_code,
    pb.product_name,
    pb.status,
    pb.actual_quantity,
    pb.start_time
FROM production_batches pb
INNER JOIN production_lines pl ON pb.line_id = pl.id
WHERE pb.status = 'in_progress'
ORDER BY pl.line_name, pb.start_time;
```

**ExplicaciÃ³n**:
- `INNER JOIN`: Combina filas cuando hay match en ambas tablas
- `ON pb.line_id = pl.id`: CondiciÃ³n de uniÃ³n (Foreign Key)
- Prefijos `pb.` y `pl.`: Alias para evitar ambigÃ¼edad
- Resultado: Una "tabla virtual" combinando datos de ambas fuentes

**VisualizaciÃ³n Mental**:
```
production_lines         production_batches
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ id â”‚ line_name â”‚      â”‚ id â”‚ line_id â”‚ batch_..â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1  â”‚ Line A    â”‚ â†â”€â”€â”€â”€â”¤ 1  â”‚    1    â”‚ ...     â”‚
â”‚ 2  â”‚ Line B    â”‚      â”‚ 2  â”‚    1    â”‚ ...     â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ 3  â”‚    2    â”‚ ...     â”‚
                        â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â””â”€ FK apunta a PK
```

**Concepto Clave**: JOIN materializa relaciones definidas por Foreign Keys.

---

### 3. AgregaciÃ³n con GROUP BY

**Objetivo PedagÃ³gico**: Entender agregaciones y agrupamiento

```sql
-- Resumen de producciÃ³n por lÃ­nea
SELECT 
    pl.line_name,
    COUNT(pb.id) as total_batches,
    SUM(pb.actual_quantity) as total_units_produced,
    AVG(pb.actual_quantity) as avg_units_per_batch,
    MIN(pb.start_time) as first_batch,
    MAX(pb.start_time) as last_batch
FROM production_lines pl
LEFT JOIN production_batches pb ON pl.id = pb.line_id
GROUP BY pl.id, pl.line_name
ORDER BY total_units_produced DESC;
```

**ExplicaciÃ³n**:
- `COUNT(pb.id)`: Cuenta batches por lÃ­nea
- `SUM(pb.actual_quantity)`: Suma total de unidades
- `AVG()`: Promedio de unidades por batch
- `GROUP BY`: Agrupa filas por lÃ­nea antes de agregar
- `LEFT JOIN`: Incluye lÃ­neas sin batches (vs INNER JOIN)

**Resultado Esperado**:
```
line_name | total_batches | total_units_produced | avg_units_per_batch | first_batch         | last_batch
----------|---------------|----------------------|---------------------|---------------------|-------------------
Line A    | 5             | 7500                 | 1500.00             | 2026-02-01 06:00:00 | 2026-02-03 08:00:00
Line B    | 3             | 4000                 | 1333.33             | 2026-02-01 14:00:00 | 2026-02-03 10:00:00
```

**Concepto Clave**: Agregaciones transforman mÃºltiples filas en valores sumarios.

---

### 4. Subconsulta (Subquery)

**Objetivo PedagÃ³gico**: Queries anidadas para lÃ³gica compleja

```sql
-- Batches con calidad superior al promedio general
SELECT 
    batch_code,
    product_name,
    actual_quantity,
    (SELECT AVG(quality_score) 
     FROM quality_inspections qi 
     WHERE qi.batch_id = pb.id) as avg_quality
FROM production_batches pb
WHERE EXISTS (
    SELECT 1 
    FROM quality_inspections qi2 
    WHERE qi2.batch_id = pb.id 
      AND qi2.quality_score > (
          SELECT AVG(quality_score) 
          FROM quality_inspections
      )
)
ORDER BY avg_quality DESC;
```

**ExplicaciÃ³n**:
- Subquery en SELECT: Calcula avg_quality por batch
- Subquery en WHERE con EXISTS: Filtra batches con inspecciones sobre promedio
- Subquery anidada: Calcula promedio general de calidad
- EvaluaciÃ³n: Subqueries se ejecutan por cada fila (correlacionadas)

**Concepto Clave**: Subqueries permiten lÃ³gica multi-nivel pero pueden ser lentas.

---

### 5. TransacciÃ³n COMMIT (ACID)

**Objetivo PedagÃ³gico**: Demostrar Atomicidad y Durabilidad

```sql
-- Registrar lote completo con eventos
START TRANSACTION;

-- Paso 1: Crear batch
INSERT INTO production_batches (
    line_id, 
    batch_code, 
    product_name, 
    target_quantity, 
    status,
    start_time
) VALUES (
    1,
    'BATCH_2026_200',
    'Widget Premium',
    2000,
    'in_progress',
    NOW()
);

-- Capturar ID del batch reciÃ©n creado
SET @new_batch_id = LAST_INSERT_ID();

-- Paso 2: Registrar evento de inicio
INSERT INTO production_events (
    batch_id,
    event_type,
    event_time,
    description
) VALUES (
    @new_batch_id,
    'start',
    NOW(),
    'Batch iniciado automÃ¡ticamente'
);

-- Si todo OK, guardar permanentemente
COMMIT;

-- Verificar que TODO se guardÃ³
SELECT * FROM production_batches WHERE batch_code = 'BATCH_2026_200';
SELECT * FROM production_events WHERE batch_id = @new_batch_id;
```

**ExplicaciÃ³n**:
- `START TRANSACTION`: Inicia bloque atÃ³mico
- `LAST_INSERT_ID()`: Captura ID auto-generado
- `COMMIT`: Hace cambios permanentes y durables
- Si falla cualquier INSERT â†’ todo se descarta automÃ¡ticamente

**Concepto Clave**: TODO o NADA. No puede quedar batch sin evento o evento sin batch.

**ACID Demostrado**:
- âœ… **A**tomicidad: 2 INSERTs son unidad indivisible
- âœ… **C**onsistencia: Foreign keys se mantienen vÃ¡lidos
- âœ… **D**urabilidad: Post-COMMIT, datos sobreviven fallo elÃ©ctrico

---

### 6. TransacciÃ³n ROLLBACK (Error Handling)

**Objetivo PedagÃ³gico**: Demostrar recuperaciÃ³n de errores

```sql
-- TransacciÃ³n que FALLARÃ intencionalmente
START TRANSACTION;

-- Paso 1: INSERT vÃ¡lido
INSERT INTO production_batches (
    line_id, 
    batch_code, 
    product_name, 
    target_quantity, 
    status,
    start_time
) VALUES (
    1,
    'BATCH_2026_FAIL',
    'Widget Test',
    1000,
    'in_progress',
    NOW()
);

SET @fail_batch_id = LAST_INSERT_ID();

-- Paso 2: INSERT que VIOLA constraint (quality > 10)
INSERT INTO quality_inspections (
    batch_id,
    inspector_name,
    quality_score,  -- âŒ Intentar poner 15 (mÃ¡ximo es 10)
    inspection_time
) VALUES (
    @fail_batch_id,
    'Inspector Test',
    15.0,  -- âŒ INVÃLIDO
    NOW()
);

-- Este COMMIT nunca se alcanzarÃ¡ porque error anterior
COMMIT;
```

**Lo Que Pasa**:
```
ERROR 3819 (HY000): Check constraint 'quality_inspections_chk_1' is violated.
```

**DespuÃ©s del Error**:
```sql
-- Verificar: el batch NO existe (ROLLBACK automÃ¡tico)
SELECT * FROM production_batches WHERE batch_code = 'BATCH_2026_FAIL';
-- Resultado: 0 rows
```

**Concepto Clave**: Error â†’ ROLLBACK automÃ¡tico. Sistema previene corrupciÃ³n de datos.

---

### 7. ViolaciÃ³n Foreign Key Constraint

**Objetivo PedagÃ³gico**: Entender integridad referencial

```sql
-- Intentar borrar lÃ­nea de producciÃ³n con batches dependientes
DELETE FROM production_lines WHERE id = 1;
```

**Error Esperado**:
```
ERROR 1451 (23000): Cannot delete or update a parent row: 
a foreign key constraint fails (`iiot_db`.`production_batches`, 
CONSTRAINT `production_batches_ibfk_1` FOREIGN KEY (`line_id`) 
REFERENCES `production_lines` (`id`))
```

**ExplicaciÃ³n Visual**:
```
production_lines (PARENT)          production_batches (CHILD)
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1  â”‚ Line A    â”‚ â† FK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ ...â”‚    1    â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†‘                                   â”‚
     â””â”€ NO PUEDES BORRAR              Tiene
        mientras existan              dependencias
        referencias
```

**SoluciÃ³n Correcta**:
```sql
-- OpciÃ³n 1: Borrar dependencias primero
DELETE FROM production_batches WHERE line_id = 1;
DELETE FROM production_lines WHERE id = 1;

-- OpciÃ³n 2: Usar CASCADE (si FK fue definido con ON DELETE CASCADE)
-- BorrarÃ­a lÃ­nea Y batches automÃ¡ticamente

-- OpciÃ³n 3: UPDATE en vez de DELETE
UPDATE production_batches SET line_id = 2 WHERE line_id = 1;
DELETE FROM production_lines WHERE id = 1;
```

**Concepto Clave**: Base de datos es guardia de seguridad que previene huÃ©rfanos.

---

### 8. Stored Procedure (LÃ³gica Compleja)

**Objetivo PedagÃ³gico**: Encapsular lÃ³gica de negocio en BD

```sql
-- Llamar stored procedure existente
CALL sp_create_batch_with_validation(
    1,                    -- line_id
    'BATCH_2026_300',     -- batch_code
    'Widget Deluxe',      -- product_name  
    2500,                 -- target_quantity
    8.0                   -- quality_threshold
);
```

**Ver definiciÃ³n del procedure** (opcional, para entender internals):
```sql
SHOW CREATE PROCEDURE sp_create_batch_with_validation;
```

**Lo Que Hace Internamente**:
1. Valida que `line_id` existe
2. Valida que `batch_code` no estÃ¡ duplicado
3. Valida que `quality_threshold` estÃ¡ entre 0-10
4. Si todo OK: INSERT batch + INSERT evento en transacciÃ³n
5. Si cualquier validaciÃ³n falla: ROLLBACK con mensaje error

**Ventajas**:
- âœ… LÃ³gica centralizada (no repetir en cada app)
- âœ… Performance (ejecuta server-side)
- âœ… Seguridad (users solo ejecutan procedure, no acceso directo)

**Concepto Clave**: Stored procedures = funciones que viven en la BD.

---

### 9. VIEW (Tabla Virtual)

**Objetivo PedagÃ³gico**: Simplificar queries complejas recurrentes

```sql
-- Usar view pre-definida
SELECT * FROM v_production_summary;
```

**Resultado**:
```
batch_code       | line_name | product_name | status      | total_quantity | inspections_count | avg_quality
-----------------|-----------|--------------|-------------|----------------|-------------------|-------------
BATCH_2026_001   | Line A    | Widget A     | completed   | 1500           | 2                 | 8.50
BATCH_2026_002   | Line A    | Widget B     | in_progress | 750            | 1                 | 9.00
...
```

**Ver definiciÃ³n de la view**:
```sql
SHOW CREATE VIEW v_production_summary;
```

**Internamente**:
```sql
CREATE VIEW v_production_summary AS
SELECT 
    pb.batch_code,
    pl.line_name,
    pb.product_name,
    pb.status,
    pb.actual_quantity as total_quantity,
    COUNT(qi.id) as inspections_count,
    AVG(qi.quality_score) as avg_quality
FROM production_batches pb
JOIN production_lines pl ON pb.line_id = pl.id
LEFT JOIN quality_inspections qi ON pb.id = qi.batch_id
GROUP BY pb.id, pb.batch_code, pl.line_name, pb.product_name, pb.status, pb.actual_quantity;
```

**Concepto Clave**: VIEW = query guardada como si fuera tabla. No almacena datos, ejecuta query cada vez.

---

### 10. Query con Parsing JSON (MQTT Logs)

**Objetivo PedagÃ³gico**: Manejar datos semi-estructurados en SQL

```sql
-- Extraer temperatura promedio de mensajes MQTT loggeados
SELECT 
    DATE(timestamp) as date,
    topic,
    COUNT(*) as message_count,
    AVG(CAST(JSON_EXTRACT(payload, '$.value') AS DECIMAL(10,2))) as avg_value,
    MIN(CAST(JSON_EXTRACT(payload, '$.value') AS DECIMAL(10,2))) as min_value,
    MAX(CAST(JSON_EXTRACT(payload, '$.value') AS DECIMAL(10,2))) as max_value
FROM mqtt_messages_log
WHERE topic = 'iiot/sensors/temperature'
  AND timestamp >= DATE_SUB(NOW(), INTERVAL 24 HOUR)
GROUP BY DATE(timestamp), topic
ORDER BY date DESC;
```

**ExplicaciÃ³n**:
- `JSON_EXTRACT(payload, '$.value')`: Extrae campo 'value' del JSON
- `CAST(... AS DECIMAL)`: Convierte texto a nÃºmero
- Agrupa por dÃ­a para resumen diario

**Resultado**:
```
date       | topic                    | message_count | avg_value | min_value | max_value
-----------|--------------------------|---------------|-----------|-----------|----------
2026-02-03 | iiot/sensors/temperature | 86400         | 65.34     | 20.15     | 99.87
2026-02-02 | iiot/sensors/temperature | 86400         | 64.92     | 20.45     | 98.34
```

**Concepto Clave**: SQL puede manejar JSON pero no es Ã³ptimo (vs document DB). Ãštil para logs/auditorÃ­a.

---

## â° Consultas InfluxDB (Flux)

### 1. Query BÃ¡sica Time-Series

**Objetivo PedagÃ³gico**: Estructura bÃ¡sica Flux

```flux
from(bucket: "iiot_sensors")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
```

**ExplicaciÃ³n LÃ­nea por LÃ­nea**:
- `from(bucket: ...)`: Fuente de datos (equivalente a FROM tabla)
- `|>`: Pipe operator - pasa resultado a siguiente funciÃ³n
- `range(start: -1h)`: Filtro temporal (Ãºltima hora)
- `filter()`: Filtros adicionales (measurement = tipo de sensor, field = columna)

**Resultado**:
```
_time                _measurement  _field  _value  sensor_id
-------------------  ------------  ------  ------  ----------
2026-02-03T09:00:00Z temperature   value   65.2    TEMP_001
2026-02-03T09:00:01Z temperature   value   65.5    TEMP_001
2026-02-03T09:00:02Z temperature   value   66.1    TEMP_001
... (3,600 filas)
```

**Concepto Clave**: Flux es funcional - pipeline de transformaciones encadenadas.

---

### 2. AgregaciÃ³n Temporal (Mean)

**Objetivo PedagÃ³gico**: Resumir datos en ventana temporal

```flux
from(bucket: "iiot_sensors")
  |> range(start: -24h)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
  |> mean()
```

**Resultado**:
```
_value
------
65.34
```

**ExplicaciÃ³n**:
- `mean()`: Promedio de TODOS los valores en el rango
- Sin `group()`: Agrega todo en un solo valor
- Procesa ~86,400 registros (1/seg x 24h) en milisegundos

**Variaciones**:
```flux
// Otras agregaciones
|> max()  // MÃ¡ximo
|> min()  // MÃ­nimo
|> count()  // Cantidad de registros
|> sum()  // Suma total
|> median()  // Mediana
|> stddev()  // DesviaciÃ³n estÃ¡ndar
```

**Concepto Clave**: Agregaciones simples muy rÃ¡pidas por diseÃ±o columnar.

---

### 3. Aggregated Windows (Downsampling)

**Objetivo PedagÃ³gico**: Reducir resoluciÃ³n temporal

```flux
from(bucket: "iiot_sensors")
  |> range(start: -24h)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
  |> aggregateWindow(every: 5m, fn: mean, createEmpty: false)
```

**ExplicaciÃ³n**:
- `aggregateWindow(every: 5m)`: Agrupa en ventanas de 5 minutos
- `fn: mean`: Calcula promedio de cada ventana
- `createEmpty: false`: Omite ventanas sin datos

**Resultado**:
```
_time                _value
-------------------  ------
2026-02-03T09:00:00Z 65.2
2026-02-03T09:05:00Z 65.8
2026-02-03T09:10:00Z 64.9
... (288 filas para 24h)
```

**ReducciÃ³n**: 86,400 registros â†’ 288 registros (300x menos)

**Uso Real**: GrÃ¡ficos histÃ³ricos largos sin saturar frontend

**Concepto Clave**: Downsampling = sacrificar detalle por performance.

---

### 4. Multiple Sensors (Group By)

**Objetivo PedagÃ³gico**: Manejar mÃºltiples series temporales

```flux
from(bucket: "iiot_sensors")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "temperature" or r["_measurement"] == "pressure")
  |> filter(fn: (r) => r["_field"] == "value")
  |> group(columns: ["_measurement", "sensor_id"])
  |> mean()
```

**Resultado**:
```
_measurement  sensor_id    _value
------------  ----------   ------
temperature   TEMP_001     65.34
pressure      PRES_001     3.42
```

**ExplicaciÃ³n**:
- `group()`: Agrupa por measurement y sensor antes de agregar
- Sin `group()`: mezclarÃ­a temperaturas y presiones (invÃ¡lido)

**Concepto Clave**: Series temporales son independientes, agrupar para operaciones correctas.

---

### 5. DetecciÃ³n de AnomalÃ­as (Threshold)

**Objetivo PedagÃ³gico**: Alertas basadas en umbrales

```flux
from(bucket: "iiot_sensors")
  |> range(start: -15m)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
  |> filter(fn: (r) => r["_value"] > 80.0)  // ğŸš¨ Umbral crÃ­tico
  |> count()
```

**Resultado**:
```
_value
------
15  // 15 lecturas sobre 80Â°C en Ãºltimos 15 min
```

**Uso Real**: Trigger para alertas

**VariaciÃ³n - Listar Todas las AnomalÃ­as**:
```flux
from(bucket: "iiot_sensors")
  |> range(start: -15m)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
  |> filter(fn: (r) => r["_value"] > 80.0)
  |> sort(columns: ["_time"], desc: true)
  |> limit(n: 10)
```

**Concepto Clave**: Filtrado post-agregaciÃ³n para detecciÃ³n de patrones.

---

### 6. Derivada (Rate of Change)

**Objetivo PedagÃ³gico**: Detectar cambios bruscos

```flux
from(bucket: "iiot_sensors")
  |> range(start: -30m)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
  |> derivative(unit: 1m, nonNegative: false)
  |> filter(fn: (r) => r["_value"] > 5.0 or r["_value"] < -5.0)
```

**ExplicaciÃ³n**:
- `derivative()`: Calcula tasa de cambio (Â°C por minuto)
- `nonNegative: false`: Permite valores negativos (enfriamiento)
- Filtro final: Solo cambios >5Â°C/min (bruscos)

**Uso Real**: Detectar fallos de sensor o eventos anormales (puertas abiertas, fugas)

**Resultado**:
```
_time                _value
-------------------  ------
2026-02-03T09:15:32Z  7.2   // âš ï¸ Subida rÃ¡pida
2026-02-03T09:23:15Z -6.8   // âš ï¸ CaÃ­da rÃ¡pida
```

**Concepto Clave**: TSDB facilita anÃ¡lisis matemÃ¡tico de tendencias.

---

### 7. Join de MÃºltiples Measurements

**Objetivo PedagÃ³gico**: Correlacionar sensores diferentes

```flux
temp = from(bucket: "iiot_sensors")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
  |> aggregateWindow(every: 1m, fn: mean)

pressure = from(bucket: "iiot_sensors")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "pressure")
  |> filter(fn: (r) => r["_field"] == "value")
  |> aggregateWindow(every: 1m, fn: mean)

join(tables: {temp: temp, pressure: pressure}, on: ["_time"])
```

**Resultado**:
```
_time                temp_value  pressure_value
-------------------  ----------  --------------
2026-02-03T09:00:00Z 65.2        3.42
2026-02-03T09:01:00Z 65.8        3.45
...
```

**Uso Real**: AnÃ¡lisis de correlaciÃ³n (ej: temperatura alta + presiÃ³n baja = fuga)

**Concepto Clave**: Join temporal - alinear series por timestamp.

---

### 8. RetenciÃ³n y Downsampling AutomÃ¡tico (Task)

**Objetivo PedagÃ³gico**: Configurar agregaciÃ³n automÃ¡tica

```flux
// Esta es una TASK que corre periÃ³dicamente
option task = {name: "downsample_hourly", every: 1h}

from(bucket: "iiot_sensors")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> aggregateWindow(every: 1m, fn: mean)
  |> to(bucket: "iiot_sensors_hourly")  // Escribir a bucket de retenciÃ³n larga
```

**ExplicaciÃ³n**:
- Task ejecuta cada hora
- Downsample datos crudos (1/seg â†’ 1/min)
- Almacena en bucket separado con retenciÃ³n >1 aÃ±o
- Bucket original puede tener retenciÃ³n corta (30 dÃ­as)

**Estrategia de RetenciÃ³n TÃ­pica**:
```
iiot_sensors (raw)          â†’ 30 dÃ­as   â†’ 1 lectura/seg
iiot_sensors_hourly         â†’ 1 aÃ±o     â†’ 1 lectura/min
iiot_sensors_daily          â†’ 5 aÃ±os    â†’ 1 lectura/hora
```

**Concepto Clave**: Downsampling automÃ¡tico reduce costos almacenamiento 95%+.

---

### 9. Percentiles (AnÃ¡lisis EstadÃ­stico)

**Objetivo PedagÃ³gico**: Entender distribuciÃ³n de datos

```flux
from(bucket: "iiot_sensors")
  |> range(start: -24h)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
  |> quantile(q: 0.95)  // Percentil 95
```

**Resultado**:
```
_value
------
87.3  // 95% de lecturas estÃ¡n bajo 87.3Â°C
```

**Uso Real**: SLA monitoring (ej: "99% del tiempo, temp < 90Â°C")

**Variaciones**:
```flux
|> quantile(q: 0.50)  // Mediana (percentil 50)
|> quantile(q: 0.99)  // Percentil 99 (outliers)
```

**Concepto Clave**: Percentiles mÃ¡s representativos que promedio para SLAs.

---

### 10. ComparaciÃ³n Periodo Anterior (Time Shift)

**Objetivo PedagÃ³gico**: AnÃ¡lisis de tendencias

```flux
current = from(bucket: "iiot_sensors")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> mean()

previous = from(bucket: "iiot_sensors")
  |> range(start: -2h, stop: -1h)  // Hora anterior
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> mean()

// Comparar manualmente o con join
union(tables: [current, previous])
```

**Resultado**:
```
_value  _start               _stop
------  -------------------  -------------------
65.3    2026-02-03T08:00:00Z 2026-02-03T09:00:00Z  // Actual
64.8    2026-02-03T07:00:00Z 2026-02-03T08:00:00Z  // Anterior
```

**CÃ¡lculo % Cambio** (requiere map):
```flux
// Diferencia: 65.3 - 64.8 = +0.5Â°C (+0.77%)
```

**Concepto Clave**: Time shift para detectar tendencias ascendentes/descendentes.

---

## âš–ï¸ Comparaciones de Rendimiento

### Escenario: Promedio de 1 Hora de Datos

**MySQL**:
```sql
SELECT AVG(CAST(JSON_EXTRACT(payload, '$.value') AS DECIMAL(10,2))) as avg_temp
FROM mqtt_messages_log
WHERE topic = 'iiot/sensors/temperature'
  AND timestamp >= DATE_SUB(NOW(), INTERVAL 1 HOUR);
```

**InfluxDB**:
```flux
from(bucket: "iiot_sensors")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> mean()
```

**Benchmark** (3,600 registros):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trica      â”‚ MySQL      â”‚ InfluxDB     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tiempo Query â”‚ 450-800 ms â”‚ 30-80 ms     â”‚
â”‚ CPU Usado    â”‚ Alto       â”‚ Bajo         â”‚
â”‚ Rows Scanned â”‚ 3,600      â”‚ 3,600        â”‚
â”‚ Storage      â”‚ ~1.2 MB    â”‚ ~0.15 MB     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† InfluxDB: 6-10x mÃ¡s rÃ¡pido
```

**Por QuÃ© InfluxDB Gana**:
- CompresiÃ³n columnar (valores similares consecutivos)
- Ãndice temporal optimizado (B-tree para timestamps)
- Sin overhead relacional (no JOINs, no FK checks)
- Almacenamiento diseÃ±ado para append-only

---

### Escenario: Downsampling 1 AÃ±o â†’ 1 DÃ­a

**MySQL** (complejo):
```sql
SELECT 
    DATE(timestamp) as day,
    AVG(CAST(JSON_EXTRACT(payload, '$.value') AS DECIMAL)) as avg_value
FROM mqtt_messages_log
WHERE topic = 'iiot/sensors/temperature'
  AND timestamp >= DATE_SUB(NOW(), INTERVAL 1 YEAR)
GROUP BY DATE(timestamp)
ORDER BY day;
```

**InfluxDB** (nativo):
```flux
from(bucket: "iiot_sensors")
  |> range(start: -1y)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> aggregateWindow(every: 1d, fn: mean)
```

**Benchmark** (~31 millones de registros):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trica      â”‚ MySQL      â”‚ InfluxDB     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tiempo Query â”‚ 30-60 seg  â”‚ 1-3 seg      â”‚
â”‚ Rows Output  â”‚ 365        â”‚ 365          â”‚
â”‚ Complejidad  â”‚ Alta       â”‚ Baja         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† InfluxDB: 10-20x mÃ¡s rÃ¡pido
```

---

### Escenario: JOIN Relacional

**MySQL** (fuerte):
```sql
SELECT pb.batch_code, pl.line_name, COUNT(qi.id) as inspections
FROM production_batches pb
JOIN production_lines pl ON pb.line_id = pl.id
LEFT JOIN quality_inspections qi ON pb.id = qi.batch_id
GROUP BY pb.id, pb.batch_code, pl.line_name;
```

**InfluxDB** (dÃ©bil - no diseÃ±ado para esto):
```flux
// Requiere mÃºltiples queries y join manual - incÃ³modo
```

**ConclusiÃ³n**:
```
ğŸ† MySQL: DiseÃ±ado para JOINs relacionales
   InfluxDB: Posible pero no idiomÃ¡tico
```

---

## ğŸ“š Ejercicios de PrÃ¡ctica

### Ejercicio 1: SQL BÃ¡sico

**Enunciado**: Obtener todos los eventos de tipo 'error' o 'warning' de la tabla `system_alerts`, ordenados por severity (mÃ¡s alto primero).

<details>
<summary>Ver SoluciÃ³n</summary>

```sql
SELECT 
    alert_type,
    message,
    severity,
    created_at
FROM system_alerts
WHERE alert_type IN ('error', 'warning')
ORDER BY severity DESC, created_at DESC;
```
</details>

---

### Ejercicio 2: SQL JOIN

**Enunciado**: Listar todos los batches con mÃ¡s de 2 inspecciones de calidad, mostrando batch_code, cantidad de inspecciones, y calidad promedio.

<details>
<summary>Ver SoluciÃ³n</summary>

```sql
SELECT 
    pb.batch_code,
    COUNT(qi.id) as inspection_count,
    AVG(qi.quality_score) as avg_quality
FROM production_batches pb
JOIN quality_inspections qi ON pb.id = qi.batch_id
GROUP BY pb.id, pb.batch_code
HAVING COUNT(qi.id) > 2
ORDER BY avg_quality DESC;
```
</details>

---

### Ejercicio 3: Flux AgregaciÃ³n

**Enunciado**: Calcular mÃ¡ximo, mÃ­nimo y promedio de presiÃ³n en las Ãºltimas 2 horas.

<details>
<summary>Ver SoluciÃ³n</summary>

```flux
from(bucket: "iiot_sensors")
  |> range(start: -2h)
  |> filter(fn: (r) => r["_measurement"] == "pressure")
  |> filter(fn: (r) => r["_field"] == "value")
  |> group()
  |> mean()

// Para max y min, reemplazar mean() con:
// |> max()
// |> min()

// O todos a la vez:
from(bucket: "iiot_sensors")
  |> range(start: -2h)
  |> filter(fn: (r) => r["_measurement"] == "pressure")
  |> filter(fn: (r) => r["_field"] == "value")
  |> group()
  |> reduce(
      fn: (r, accumulator) => ({
        max: if r._value > accumulator.max then r._value else accumulator.max,
        min: if r._value < accumulator.min then r._value else accumulator.min,
        sum: accumulator.sum + r._value,
        count: accumulator.count + 1.0,
      }),
      identity: {max: -999999.0, min: 999999.0, sum: 0.0, count: 0.0}
    )
  |> map(fn: (r) => ({
      max: r.max,
      min: r.min,
      mean: r.sum / r.count
    }))
```
</details>

---

### Ejercicio 4: SQL TransacciÃ³n

**Enunciado**: Crear transacciÃ³n que registre un nuevo lote Y su primer evento de calidad, asegurando atomicidad.

<details>
<summary>Ver SoluciÃ³n</summary>

```sql
START TRANSACTION;

INSERT INTO production_batches (
    line_id, batch_code, product_name, 
    target_quantity, status, start_time
) VALUES (
    2, 'BATCH_EXERCISE', 'Widget Exercise', 
    1000, 'in_progress', NOW()
);

SET @batch_id = LAST_INSERT_ID();

INSERT INTO quality_inspections (
    batch_id, inspector_name, 
    quality_score, inspection_time
) VALUES (
    @batch_id, 'Inspector Rodriguez', 
    8.5, NOW()
);

COMMIT;

-- Verificar
SELECT * FROM production_batches WHERE batch_code = 'BATCH_EXERCISE';
SELECT * FROM quality_inspections WHERE batch_id = @batch_id;
```
</details>

---

### Ejercicio 5: Flux DetecciÃ³n AnomalÃ­as

**Enunciado**: Detectar todos los momentos en Ãºltimos 30 minutos donde temperatura cambiÃ³ mÃ¡s de 10Â°C en 1 minuto.

<details>
<summary>Ver SoluciÃ³n</summary>

```flux
from(bucket: "iiot_sensors")
  |> range(start: -30m)
  |> filter(fn: (r) => r["_measurement"] == "temperature")
  |> filter(fn: (r) => r["_field"] == "value")
  |> derivative(unit: 1m, nonNegative: false)
  |> filter(fn: (r) => r["_value"] > 10.0 or r["_value"] < -10.0)
  |> sort(columns: ["_time"], desc: false)
```
</details>

---

## ğŸ¯ Resumen Comparativo Final

| CaracterÃ­stica | MySQL | InfluxDB |
|----------------|-------|----------|
| **Mejor para** | Transacciones, relaciones | Series temporales |
| **ACID** | âœ… Completo | âš ï¸ Eventual consistency |
| **JOINs** | âœ… Excelente | âŒ Limitado |
| **Agregaciones Temporales** | âš ï¸ Lentas | âœ… Muy rÃ¡pidas |
| **Esquema** | RÃ­gido | Flexible (schema-less) |
| **CompresiÃ³n** | Manual | AutomÃ¡tica (8-10x) |
| **Query Language** | SQL (maduro) | Flux (moderno) |
| **Escalabilidad** | Vertical | Horizontal |
| **Uso IIoT** | Maestros, transacciones | Sensores, telemetrÃ­a |

---

## ğŸ“– Recursos Adicionales

### DocumentaciÃ³n Oficial
- **MySQL**: https://dev.mysql.com/doc/
- **InfluxDB**: https://docs.influxdata.com/
- **Flux**: https://docs.influxdata.com/flux/

### Tutoriales Interactivos
- **InfluxDB University**: https://university.influxdata.com/ (gratis)
- **MySQL Tutorial**: https://www.mysqltutorial.org/
- **SQL Zoo**: https://sqlzoo.net/

### Herramientas PrÃ¡ctica
- **Adminer**: Explorador visual MySQL
- **InfluxDB UI**: Data Explorer integrado
- **Grafana**: VisualizaciÃ³n queries

---

**Â¡Practica estas queries en el entorno Docker! ğŸš€**

_La mejor forma de aprender es ejecutando y experimentando._


---
**VersiÃ³n**: 1.0  
**Ãšltima ActualizaciÃ³n**: Febrero 2026  
**Instructor**: Christian Spana
